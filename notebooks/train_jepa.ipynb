{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# JEPA Training on Google Colab\n",
        "\n",
        "This notebook trains the JEPA model using the production package structure.\n",
        "\n",
        "## Features\n",
        "- **Dynamic Repository Cloning**: Automatically clones or updates the repository from GitHub\n",
        "- **Branch Support**: Specify any branch to use (default: `main`)\n",
        "- **Colab & Local**: Works on both Google Colab and local environments\n",
        "\n",
        "## Configuration\n",
        "Edit the `REPO_BRANCH` variable in the next cell to specify which branch to use:\n",
        "- `main` (default)\n",
        "- `feat/jepa_evaluation`\n",
        "- Any other branch name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Locally\n",
            "Moved up to project root: /Users/shamik/Documents/AV-SSL-Optimization-JEPA\n",
            "Added project root to sys.path\n"
          ]
        }
      ],
      "source": [
        "# 1. Environment Setup (Colab & Local Support)\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "# Repository configuration\n",
        "REPO_URL = \"https://github.com/shamikkarkhanis/AV-SSL-Optimization-JEPA.git\"\n",
        "REPO_BRANCH = \"main\"  # Change this to specify a different branch (e.g., \"feat/jepa_evaluation\")\n",
        "\n",
        "# Detect environment\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def clone_or_update_repo(repo_url, branch, target_path):\n",
        "    \"\"\"Clone repository or update if it already exists.\"\"\"\n",
        "    repo_name = os.path.basename(repo_url).replace('.git', '')\n",
        "    full_path = os.path.join(target_path, repo_name)\n",
        "    \n",
        "    if os.path.exists(full_path):\n",
        "        print(f\"ðŸ“‚ Repository found at {full_path}\")\n",
        "        print(f\"ðŸ”„ Checking out branch: {branch}\")\n",
        "        os.chdir(full_path)\n",
        "        \n",
        "        # Fetch latest changes\n",
        "        subprocess.run(['git', 'fetch', 'origin'], check=False, capture_output=True)\n",
        "        \n",
        "        # Checkout specified branch\n",
        "        result = subprocess.run(['git', 'checkout', branch], capture_output=True, text=True)\n",
        "        if result.returncode != 0:\n",
        "            # Try to checkout remote branch if local doesn't exist\n",
        "            subprocess.run(['git', 'checkout', '-b', branch, f'origin/{branch}'], \n",
        "                         capture_output=True, check=False)\n",
        "        \n",
        "        # Pull latest changes\n",
        "        subprocess.run(['git', 'pull', 'origin', branch], check=False, capture_output=True)\n",
        "        print(f\"âœ… Repository updated to latest {branch}\")\n",
        "    else:\n",
        "        print(f\"ðŸ“¥ Cloning repository from {repo_url} (branch: {branch})...\")\n",
        "        os.makedirs(target_path, exist_ok=True)\n",
        "        os.chdir(target_path)\n",
        "        \n",
        "        # Clone with specific branch\n",
        "        subprocess.run(['git', 'clone', '--branch', branch, '--single-branch', repo_url], \n",
        "                      check=True)\n",
        "        print(f\"âœ… Repository cloned successfully\")\n",
        "    \n",
        "    return full_path\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running on Google Colab\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Clone/update repo in Colab content directory (faster than Drive)\n",
        "    REPO_BASE_PATH = '/content'\n",
        "    REPO_PATH = clone_or_update_repo(REPO_URL, REPO_BRANCH, REPO_BASE_PATH)\n",
        "    \n",
        "    os.chdir(REPO_PATH)\n",
        "    print(f\"ðŸ“‚ Working directory set to: {os.getcwd()}\")\n",
        "    \n",
        "    # Install packages (Colab only)\n",
        "    print(\"ðŸ“¦ Installing dependencies...\")\n",
        "    !pip install -e .[dev]\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "else:\n",
        "    print(\"Running Locally\")\n",
        "    # Clone/update repo in current directory or parent\n",
        "    current_dir = os.getcwd()\n",
        "    \n",
        "    # If running from 'notebooks/' directory, clone in parent\n",
        "    if current_dir.endswith('notebooks'):\n",
        "        REPO_BASE_PATH = os.path.dirname(current_dir)\n",
        "    else:\n",
        "        REPO_BASE_PATH = current_dir\n",
        "    \n",
        "    REPO_PATH = clone_or_update_repo(REPO_URL, REPO_BRANCH, REPO_BASE_PATH)\n",
        "    os.chdir(REPO_PATH)\n",
        "    print(f\"ðŸ“‚ Working directory set to: {os.getcwd()}\")\n",
        "    \n",
        "    # Add project root to sys.path to find 'src' module\n",
        "    if os.getcwd() not in sys.path:\n",
        "        sys.path.append(os.getcwd())\n",
        "        print(\"Added project root to sys.path\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shamik/Documents/AV-SSL-Optimization-JEPA/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# 3. Load Configuration\n",
        "import yaml\n",
        "import torch\n",
        "from src.jepa.data import JEPADataset, TubeletDataset, MaskTubelet\n",
        "from src.jepa.models import JEPAModel\n",
        "from src.jepa.training import Trainer\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Load default config\n",
        "with open('configs/default.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Override config for Colab if needed\n",
        "config['training']['batch_size'] = 8  # Adjust based on GPU VRAM\n",
        "config['training']['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f\"Using device: {config['training']['device']}\")\n",
        "\n",
        "# --- Dynamic Checkpoint Directory ---\n",
        "def get_next_run_dir(base_dir):\n",
        "    from datetime import datetime\n",
        "    date_str = datetime.now().strftime('%Y-%m-%d')\n",
        "    run_dir = os.path.join(base_dir, date_str)\n",
        "    \n",
        "    if not os.path.exists(run_dir):\n",
        "        return run_dir\n",
        "    \n",
        "    i = 2\n",
        "    while True:\n",
        "        run_dir_v = f\"{run_dir}_{i}\"\n",
        "        if not os.path.exists(run_dir_v):\n",
        "            return run_dir_v\n",
        "        i += 1\n",
        "\n",
        "base_ckpt_dir = config['training'].get('checkpoint_dir', 'experiments/checkpoints')\n",
        "run_ckpt_dir = get_next_run_dir(base_ckpt_dir)\n",
        "config['training']['checkpoint_dir'] = run_ckpt_dir\n",
        "\n",
        "os.makedirs(run_ckpt_dir, exist_ok=True)\n",
        "print(f\"ðŸš€ Checkpoints will be saved to: {run_ckpt_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 134, Val samples: 34\n"
          ]
        }
      ],
      "source": [
        "# 4. Prepare Data\n",
        "mask_transform = MaskTubelet(\n",
        "    mask_ratio=config['data']['mask_ratio'],\n",
        "    patch_size=config['data']['patch_size']\n",
        ")\n",
        "\n",
        "# Load full dataset\n",
        "full_dataset = TubeletDataset(\n",
        "    manifest_path=config['data']['manifest_path'],\n",
        "    data_root=config['data'].get('data_root'),  # Handle relative paths\n",
        "    tubelet_size=config['data']['tubelet_size'],\n",
        "    transform=mask_transform\n",
        ")\n",
        "\n",
        "# Split train/val\n",
        "train_size = int(config['data']['train_split'] * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_ds, val_ds = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=config['training']['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=config['training']['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 587/587 [00:00<00:00, 1585.85it/s, Materializing param=predictor.proj.weight]                           \n"
          ]
        }
      ],
      "source": [
        "# 5. Initialize Model\n",
        "model = JEPAModel(\n",
        "    encoder_name=config['model']['encoder_name'],\n",
        "    predictor_hidden=config['model']['predictor']['hidden_dim'],\n",
        "    predictor_dropout=config['model']['predictor']['dropout'],\n",
        "    freeze_encoder=config['model']['freeze_encoder']\n",
        ")\n",
        "\n",
        "device = torch.device(config['training']['device'])\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.predictor.parameters(),  # Only optimize predictor\n",
        "    lr=float(config['training']['lr']),\n",
        "    weight_decay=float(config['training']['weight_decay'])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BENCHMARKING: Performance measurement utilities\n",
        "import time\n",
        "import json\n",
        "import statistics\n",
        "import threading\n",
        "from collections import deque\n",
        "from pathlib import Path\n",
        "\n",
        "# BENCHMARKING: Configuration\n",
        "BENCHMARK_CONFIG = {\n",
        "    'warmup_iterations': 50,      # Ignore first N iterations\n",
        "    'benchmark_iterations': 300,   # Benchmark next M iterations\n",
        "    'nvidia_smi_interval': 0.25,   # Sample nvidia-smi every 250ms (if available)\n",
        "    'enable_nvidia_smi': True,     # Enable nvidia-smi sampling (optional)\n",
        "}\n",
        "\n",
        "# BENCHMARKING: Global state for benchmarking\n",
        "benchmark_state = {\n",
        "    'step_times': deque(maxlen=BENCHMARK_CONFIG['benchmark_iterations']),\n",
        "    'throughput': deque(maxlen=BENCHMARK_CONFIG['benchmark_iterations']),\n",
        "    'gpu_samples': [],\n",
        "    'nvidia_smi_thread': None,\n",
        "    'nvidia_smi_running': False,\n",
        "    'current_iteration': 0,\n",
        "    'benchmark_started': False,\n",
        "    'peak_memory_mb': 0.0,\n",
        "}\n",
        "\n",
        "def reset_memory_stats():\n",
        "    \"\"\"BENCHMARKING: Reset CUDA memory statistics.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def get_peak_memory_mb():\n",
        "    \"\"\"BENCHMARKING: Get peak allocated memory in MB.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "    return 0.0\n",
        "\n",
        "def sample_nvidia_smi():\n",
        "    \"\"\"BENCHMARKING: Sample nvidia-smi for GPU utilization and power (optional).\"\"\"\n",
        "    if not BENCHMARK_CONFIG['enable_nvidia_smi']:\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        import subprocess\n",
        "        result = subprocess.run(\n",
        "            ['nvidia-smi', '--query-gpu=utilization.gpu,power.draw', '--format=csv,noheader,nounits'],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=1.0\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            parts = result.stdout.strip().split(', ')\n",
        "            if len(parts) == 2:\n",
        "                return {\n",
        "                    'utilization_gpu': float(parts[0]),\n",
        "                    'power_draw': float(parts[1]),\n",
        "                    'timestamp': time.perf_counter()\n",
        "                }\n",
        "    except (FileNotFoundError, subprocess.TimeoutExpired, ValueError):\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def nvidia_smi_sampler():\n",
        "    \"\"\"BENCHMARKING: Background thread to sample nvidia-smi periodically.\"\"\"\n",
        "    while benchmark_state['nvidia_smi_running']:\n",
        "        sample = sample_nvidia_smi()\n",
        "        if sample:\n",
        "            benchmark_state['gpu_samples'].append(sample)\n",
        "        time.sleep(BENCHMARK_CONFIG['nvidia_smi_interval'])\n",
        "\n",
        "def start_nvidia_smi_sampling():\n",
        "    \"\"\"BENCHMARKING: Start background nvidia-smi sampling.\"\"\"\n",
        "    if BENCHMARK_CONFIG['enable_nvidia_smi'] and torch.cuda.is_available():\n",
        "        benchmark_state['nvidia_smi_running'] = True\n",
        "        benchmark_state['gpu_samples'] = []\n",
        "        benchmark_state['nvidia_smi_thread'] = threading.Thread(target=nvidia_smi_sampler, daemon=True)\n",
        "        benchmark_state['nvidia_smi_thread'].start()\n",
        "\n",
        "def stop_nvidia_smi_sampling():\n",
        "    \"\"\"BENCHMARKING: Stop background nvidia-smi sampling.\"\"\"\n",
        "    benchmark_state['nvidia_smi_running'] = False\n",
        "    if benchmark_state['nvidia_smi_thread']:\n",
        "        benchmark_state['nvidia_smi_thread'].join(timeout=1.0)\n",
        "\n",
        "def benchmarked_train_epoch(trainer, loader, epoch, batch_size):\n",
        "    \"\"\"\n",
        "    BENCHMARKING: Training epoch with per-iteration benchmarking.\n",
        "    Replicates trainer.train_epoch() logic but with instrumentation.\n",
        "    \"\"\"\n",
        "    from src.jepa.training.losses import jepa_loss\n",
        "    from tqdm import tqdm\n",
        "    \n",
        "    trainer.model.train()\n",
        "    trainer.model.encoder.eval()\n",
        "    trainer.model.predictor.train()\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    \n",
        "    # BENCHMARKING: Reset memory stats before training (only once, at start)\n",
        "    if epoch == 0 and not benchmark_state['benchmark_started']:\n",
        "        reset_memory_stats()\n",
        "        benchmark_state['benchmark_started'] = True\n",
        "        benchmark_state['current_iteration'] = 0  # Initialize global counter\n",
        "        start_nvidia_smi_sampling()\n",
        "    \n",
        "    pbar = tqdm(loader, desc=f\"Train Epoch {epoch}\")\n",
        "    for batch in pbar:\n",
        "        iter_start = time.perf_counter()\n",
        "        \n",
        "        # BENCHMARKING: Synchronize before timing\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        \n",
        "        # Move data to device\n",
        "        masked = batch[\"masked_frames\"].to(trainer.device)\n",
        "        clean = batch[\"clean_frames\"].to(trainer.device)\n",
        "        mask_frac = batch[\"mask_frac\"].to(trainer.device)\n",
        "        \n",
        "        # Forward pass\n",
        "        clean_emb, pred_emb = trainer.model(clean, masked, mask_frac)\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss = jepa_loss(pred_emb, clean_emb, normalize=True)\n",
        "        \n",
        "        # Backward pass\n",
        "        trainer.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        trainer.optimizer.step()\n",
        "        \n",
        "        # BENCHMARKING: Synchronize after computation\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        \n",
        "        iter_end = time.perf_counter()\n",
        "        iter_time_ms = (iter_end - iter_start) * 1000.0\n",
        "        \n",
        "        # Update metrics\n",
        "        loss_val = loss.item()\n",
        "        total_loss += loss_val\n",
        "        pbar.set_postfix({\"loss\": f\"{loss_val:.4f}\"})\n",
        "        \n",
        "        # BENCHMARKING: Collect metrics after warmup\n",
        "        if benchmark_state['current_iteration'] >= BENCHMARK_CONFIG['warmup_iterations']:\n",
        "            if len(benchmark_state['step_times']) < BENCHMARK_CONFIG['benchmark_iterations']:\n",
        "                benchmark_state['step_times'].append(iter_time_ms)\n",
        "                # Calculate throughput: batch_size images per iter_time_ms\n",
        "                images_per_sec = (batch_size * 1000.0) / iter_time_ms if iter_time_ms > 0 else 0.0\n",
        "                benchmark_state['throughput'].append(images_per_sec)\n",
        "                \n",
        "                # Update peak memory\n",
        "                current_peak = get_peak_memory_mb()\n",
        "                benchmark_state['peak_memory_mb'] = max(benchmark_state['peak_memory_mb'], current_peak)\n",
        "        \n",
        "        benchmark_state['current_iteration'] += 1\n",
        "    \n",
        "    # BENCHMARKING: Stop sampling if benchmark window is complete\n",
        "    if len(benchmark_state['step_times']) >= BENCHMARK_CONFIG['benchmark_iterations']:\n",
        "        stop_nvidia_smi_sampling()\n",
        "    \n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def print_benchmark_summary():\n",
        "    \"\"\"BENCHMARKING: Print concise benchmark summary.\"\"\"\n",
        "    if len(benchmark_state['step_times']) == 0:\n",
        "        print(\"\\nâš ï¸  BENCHMARKING: No benchmark data collected yet.\")\n",
        "        return\n",
        "    \n",
        "    step_times = list(benchmark_state['step_times'])\n",
        "    throughputs = list(benchmark_state['throughput'])\n",
        "    \n",
        "    mean_step_time = statistics.mean(step_times)\n",
        "    std_step_time = statistics.stdev(step_times) if len(step_times) > 1 else 0.0\n",
        "    \n",
        "    mean_throughput = statistics.mean(throughputs)\n",
        "    std_throughput = statistics.stdev(throughputs) if len(throughputs) > 1 else 0.0\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BENCHMARKING: Upstream Training Performance Summary\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Benchmark Window: {len(step_times)} iterations\")\n",
        "    print(f\"Warmup Iterations: {BENCHMARK_CONFIG['warmup_iterations']}\")\n",
        "    print()\n",
        "    print(\"Throughput:\")\n",
        "    print(f\"  Images/sec: {mean_throughput:.2f} Â± {std_throughput:.2f}\")\n",
        "    print(f\"  Clips/sec:  {mean_throughput:.2f} Â± {std_throughput:.2f}  (assuming 1 clip = 1 image)\")\n",
        "    print()\n",
        "    print(\"Step Time:\")\n",
        "    print(f\"  Average: {mean_step_time:.2f} Â± {std_step_time:.2f} ms/iter\")\n",
        "    print()\n",
        "    print(\"GPU Memory:\")\n",
        "    print(f\"  Peak Allocated VRAM: {benchmark_state['peak_memory_mb']:.2f} MB\")\n",
        "    \n",
        "    # BENCHMARKING: Optional nvidia-smi summary\n",
        "    if benchmark_state['gpu_samples']:\n",
        "        utilizations = [s['utilization_gpu'] for s in benchmark_state['gpu_samples']]\n",
        "        powers = [s['power_draw'] for s in benchmark_state['gpu_samples']]\n",
        "        mean_util = statistics.mean(utilizations)\n",
        "        mean_power = statistics.mean(powers)\n",
        "        \n",
        "        # Calculate energy per iteration (rough estimate)\n",
        "        if len(step_times) > 0:\n",
        "            avg_step_time_sec = mean_step_time / 1000.0\n",
        "            energy_per_iter = mean_power * avg_step_time_sec / 1000.0  # Joules per iteration\n",
        "        \n",
        "        print()\n",
        "        print(\"GPU Utilization (nvidia-smi):\")\n",
        "        print(f\"  Average GPU Utilization: {mean_util:.1f}%\")\n",
        "        print(f\"  Average Power Draw: {mean_power:.2f} W\")\n",
        "        if len(step_times) > 0:\n",
        "            print(f\"  Estimated Energy per Iteration: {energy_per_iter:.4f} J\")\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "\n",
        "def save_benchmark_results(output_dir):\n",
        "    \"\"\"BENCHMARKING: Save benchmark results to JSON file.\"\"\"\n",
        "    if len(benchmark_state['step_times']) == 0:\n",
        "        return\n",
        "    \n",
        "    step_times = list(benchmark_state['step_times'])\n",
        "    throughputs = list(benchmark_state['throughput'])\n",
        "    \n",
        "    results = {\n",
        "        'config': BENCHMARK_CONFIG,\n",
        "        'summary': {\n",
        "            'mean_step_time_ms': statistics.mean(step_times),\n",
        "            'std_step_time_ms': statistics.stdev(step_times) if len(step_times) > 1 else 0.0,\n",
        "            'mean_throughput_images_per_sec': statistics.mean(throughputs),\n",
        "            'std_throughput_images_per_sec': statistics.stdev(throughputs) if len(throughputs) > 1 else 0.0,\n",
        "            'peak_memory_mb': benchmark_state['peak_memory_mb'],\n",
        "            'benchmark_iterations': len(step_times),\n",
        "        },\n",
        "        'raw_data': {\n",
        "            'step_times_ms': step_times,\n",
        "            'throughput_images_per_sec': throughputs,\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Add nvidia-smi data if available\n",
        "    if benchmark_state['gpu_samples']:\n",
        "        utilizations = [s['utilization_gpu'] for s in benchmark_state['gpu_samples']]\n",
        "        powers = [s['power_draw'] for s in benchmark_state['gpu_samples']]\n",
        "        results['summary']['mean_gpu_utilization_percent'] = statistics.mean(utilizations)\n",
        "        results['summary']['mean_power_draw_watts'] = statistics.mean(powers)\n",
        "        results['raw_data']['gpu_samples'] = benchmark_state['gpu_samples']\n",
        "    \n",
        "    output_path = Path(output_dir) / 'benchmark_results.json'\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"\\nðŸ’¾ BENCHMARKING: Results saved to {output_path}\")\n",
        "\n",
        "print(\"âœ… BENCHMARKING: Performance measurement utilities loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:55<00:00,  3.28s/it, loss=0.0166]\n",
            "Val Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.64s/it, loss=0.0150]\n",
            "Train Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.12s/it, loss=0.0130]\n",
            "Val Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.68s/it, loss=0.0117]\n",
            "Train Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.16s/it, loss=0.0125]\n",
            "Val Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.68s/it, loss=0.0098]\n",
            "Train Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:56<00:00,  3.33s/it, loss=0.0099]\n",
            "Val Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.70s/it, loss=0.0086]\n",
            "Train Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:58<00:00,  3.42s/it, loss=0.0091]\n",
            "Val Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.29s/it, loss=0.0080]\n",
            "Train Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:57<00:00,  3.36s/it, loss=0.0091]\n",
            "Val Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.66s/it, loss=0.0072]\n",
            "Train Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.12s/it, loss=0.0082]\n",
            "Val Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.61s/it, loss=0.0067]\n",
            "Train Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:51<00:00,  3.02s/it, loss=0.0076]\n",
            "Val Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22<00:00,  4.58s/it, loss=0.0064]\n",
            "Train Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:51<00:00,  3.03s/it, loss=0.0080]\n",
            "Val Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:24<00:00,  4.92s/it, loss=0.0060]\n",
            "Train Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.17s/it, loss=0.0070]\n",
            "Val Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.65s/it, loss=0.0058]\n",
            "Train Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:54<00:00,  3.20s/it, loss=0.0066]\n",
            "Val Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  5.09s/it, loss=0.0062]\n",
            "Train Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:56<00:00,  3.31s/it, loss=0.0063]\n",
            "Val Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31<00:00,  6.29s/it, loss=0.0052]\n",
            "Train Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:54<00:00,  3.19s/it, loss=0.0068]\n",
            "Val Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22<00:00,  4.48s/it, loss=0.0052]\n",
            "Train Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:51<00:00,  3.05s/it, loss=0.0059]\n",
            "Val Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  5.01s/it, loss=0.0052]\n",
            "Train Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:56<00:00,  3.30s/it, loss=0.0060]\n",
            "Val Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.78s/it, loss=0.0056]\n",
            "Train Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.12s/it, loss=0.0053]\n",
            "Val Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:24<00:00,  4.94s/it, loss=0.0047]\n",
            "Train Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:57<00:00,  3.40s/it, loss=0.0054]\n",
            "Val Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.54s/it, loss=0.0047]\n",
            "Train Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.17s/it, loss=0.0061]\n",
            "Val Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.65s/it, loss=0.0052]\n",
            "Train Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:51<00:00,  3.05s/it, loss=0.0061]\n",
            "Val Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.78s/it, loss=0.0049]\n",
            "Train Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:54<00:00,  3.18s/it, loss=0.0052]\n",
            "Val Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.62s/it, loss=0.0045]\n",
            "Train Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:56<00:00,  3.31s/it, loss=0.0062]\n",
            "Val Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:24<00:00,  4.86s/it, loss=0.0045]\n",
            "Train Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.17s/it, loss=0.0060]\n",
            "Val Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.62s/it, loss=0.0048]\n",
            "Train Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:51<00:00,  3.02s/it, loss=0.0051]\n",
            "Val Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.62s/it, loss=0.0049]\n",
            "Train Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:51<00:00,  3.00s/it, loss=0.0056]\n",
            "Val Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.61s/it, loss=0.0047]\n",
            "Train Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:50<00:00,  2.99s/it, loss=0.0057]\n",
            "Val Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22<00:00,  4.55s/it, loss=0.0046]\n",
            "Train Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.12s/it, loss=0.0051]\n",
            "Val Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.60s/it, loss=0.0043]\n",
            "Train Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:52<00:00,  3.09s/it, loss=0.0054]\n",
            "Val Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.66s/it, loss=0.0046]\n",
            "Train Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:52<00:00,  3.09s/it, loss=0.0050]\n",
            "Val Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.66s/it, loss=0.0045]\n",
            "Train Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:52<00:00,  3.08s/it, loss=0.0049]\n",
            "Val Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.69s/it, loss=0.0047]\n",
            "Train Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:54<00:00,  3.22s/it, loss=0.0047]\n",
            "Val Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.77s/it, loss=0.0046]\n"
          ]
        }
      ],
      "source": [
        "# 6. Training Loop\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    checkpoint_dir=config['training']['checkpoint_dir']\n",
        ")\n",
        "\n",
        "num_epochs = config['training']['epochs']\n",
        "best_loss = float('inf')\n",
        "batch_size = config['training']['batch_size']\n",
        "\n",
        "# BENCHMARKING: Use benchmarked training function for accurate measurements\n",
        "for epoch in range(num_epochs):\n",
        "    # BENCHMARKING: Use benchmarked_train_epoch instead of trainer.train_epoch\n",
        "    # This replicates the exact same training logic but with performance instrumentation\n",
        "    train_loss = benchmarked_train_epoch(trainer, train_loader, epoch, batch_size)\n",
        "    \n",
        "    # Validate (no benchmarking on validation)\n",
        "    val_loss = trainer.validate_epoch(val_loader, epoch)\n",
        "    \n",
        "    # Checkpoint\n",
        "    is_best = val_loss < best_loss\n",
        "    if is_best:\n",
        "        best_loss = val_loss\n",
        "        \n",
        "    if (epoch + 1) % config['training']['checkpoint_every'] == 0 or is_best:\n",
        "        trainer.save_checkpoint(epoch, val_loss, is_best, config)\n",
        "    \n",
        "    # BENCHMARKING: Print summary and save results when benchmark window is complete\n",
        "    if len(benchmark_state['step_times']) >= BENCHMARK_CONFIG['benchmark_iterations']:\n",
        "        if not benchmark_state.get('_summary_printed', False):\n",
        "            print_benchmark_summary()\n",
        "            save_benchmark_results(config['training']['checkpoint_dir'])\n",
        "            benchmark_state['_summary_printed'] = True\n",
        "\n",
        "# BENCHMARKING: Print final summary if training completes before benchmark window\n",
        "if len(benchmark_state['step_times']) > 0 and not benchmark_state.get('_summary_printed', False):\n",
        "    print_benchmark_summary()\n",
        "    save_benchmark_results(config['training']['checkpoint_dir'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
