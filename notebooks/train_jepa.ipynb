{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# JEPA Training on Google Colab\n",
        "\n",
        "This notebook trains the JEPA model using the production package structure.\n",
        "\n",
        "## Features\n",
        "- **Dynamic Repository Cloning**: Automatically clones or updates the repository from GitHub\n",
        "- **Branch Support**: Specify any branch to use (default: `main`)\n",
        "- **Colab & Local**: Works on both Google Colab and local environments\n",
        "\n",
        "## Configuration\n",
        "Edit the `REPO_BRANCH` variable in the next cell to specify which branch to use:\n",
        "- `main` (default)\n",
        "- `feat/jepa_evaluation`\n",
        "- Any other branch name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ðŸ“‚ Repository found at /content/AV-SSL-Optimization-JEPA. Updating...\n",
            "ðŸ“¦ Extracting dataset to local runtime...\n",
            "ðŸš€ Ready! Working Directory: /content/AV-SSL-Optimization-JEPA\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "# 1. Configuration\n",
        "REPO_URL = \"https://github.com/shamikkarkhanis/AV-SSL-Optimization-JEPA.git\"\n",
        "REPO_BRANCH = \"feat/jepa_evaluation\" \n",
        "DRIVE_DATA_ZIP = '/content/drive/MyDrive/URP S26/v1.0-mini.zip'\n",
        "LOCAL_DATA_DIR = '/content/data_local'\n",
        "\n",
        "# 2. Environment Detection\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def clone_or_update_repo(repo_url, branch, target_base_path):\n",
        "    \"\"\"\n",
        "    Clones the repo into the target path and returns the absolute path \n",
        "    to the repository root (REPO_PATH).\n",
        "    \"\"\"\n",
        "    repo_name = os.path.basename(repo_url).replace('.git', '')\n",
        "    repo_full_path = os.path.join(target_base_path, repo_name)\n",
        "    \n",
        "    if os.path.exists(repo_full_path):\n",
        "        print(f\"ðŸ“‚ Repository found at {repo_full_path}. Updating...\")\n",
        "        os.chdir(repo_full_path)\n",
        "        subprocess.run(['git', 'fetch', 'origin'], capture_output=True)\n",
        "        subprocess.run(['git', 'checkout', branch], capture_output=True)\n",
        "        subprocess.run(['git', 'pull', 'origin', branch], capture_output=True)\n",
        "    else:\n",
        "        print(f\"ðŸ“¥ Cloning {branch} into {target_base_path}...\")\n",
        "        os.makedirs(target_base_path, exist_ok=True)\n",
        "        os.chdir(target_base_path)\n",
        "        subprocess.run(['git', 'clone', '--branch', branch, '--single-branch', repo_url], check=True)\n",
        "    \n",
        "    return repo_full_path\n",
        "\n",
        "# 3. Execution Logic\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Define REPO_PATH by cloning into /content\n",
        "    REPO_PATH = clone_or_update_repo(REPO_URL, REPO_BRANCH, '/content')\n",
        "    \n",
        "    # Handle Data Linking\n",
        "    if os.path.exists(DRIVE_DATA_ZIP):\n",
        "        # Unzip to local disk for fast I/O\n",
        "        if not os.path.exists(LOCAL_DATA_DIR):\n",
        "            print(\"ðŸ“¦ Extracting dataset to local runtime...\")\n",
        "            !unzip -q \"{DRIVE_DATA_ZIP}\" -d {LOCAL_DATA_DIR}\n",
        "        \n",
        "        # Define where the repo expects data\n",
        "        RAW_DATA_TARGET = os.path.join(REPO_PATH, 'data/raw')\n",
        "        os.makedirs(os.path.dirname(RAW_DATA_TARGET), exist_ok=True)\n",
        "        \n",
        "        # Create Symlink: code looks at REPO/data/raw -> finds files in /content/data_local\n",
        "        if not os.path.exists(RAW_DATA_TARGET):\n",
        "            os.symlink(LOCAL_DATA_DIR, RAW_DATA_TARGET)\n",
        "            print(f\"âœ… Symlink created: {RAW_DATA_TARGET} -> {LOCAL_DATA_DIR}\")\n",
        "\n",
        "else:\n",
        "    # Local Logic: Find the root based on where this script is running\n",
        "    REPO_PATH = os.getcwd()\n",
        "    # Optional: Walk up parents to find .git if you aren't in the root\n",
        "    while REPO_PATH != \"/\" and not os.path.exists(os.path.join(REPO_PATH, \".git\")):\n",
        "        REPO_PATH = os.path.dirname(REPO_PATH)\n",
        "    print(f\"ðŸ’» Running locally. REPO_PATH detected as: {REPO_PATH}\")\n",
        "\n",
        "# 4. Final System Prep\n",
        "os.chdir(REPO_PATH)\n",
        "if REPO_PATH not in sys.path:\n",
        "    sys.path.append(REPO_PATH)\n",
        "\n",
        "print(f\"ðŸš€ Ready! Working Directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "ðŸš€ Checkpoints will be saved to: experiments/checkpoints/2026-02-06\n"
          ]
        }
      ],
      "source": [
        "# 3. Load Configuration\n",
        "import yaml\n",
        "import torch\n",
        "from src.jepa.data import JEPADataset, TubeletDataset, MaskTubelet\n",
        "from src.jepa.models import JEPAModel\n",
        "from src.jepa.training import Trainer\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Load default config\n",
        "with open('configs/default.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Override config for Colab if needed\n",
        "config['training']['batch_size'] = 8  # Adjust based on GPU VRAM\n",
        "config['training']['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f\"Using device: {config['training']['device']}\")\n",
        "\n",
        "# --- Dynamic Checkpoint Directory ---\n",
        "def get_next_run_dir(base_dir):\n",
        "    from datetime import datetime\n",
        "    date_str = datetime.now().strftime('%Y-%m-%d')\n",
        "    run_dir = os.path.join(base_dir, date_str)\n",
        "    \n",
        "    if not os.path.exists(run_dir):\n",
        "        return run_dir\n",
        "    \n",
        "    i = 2\n",
        "    while True:\n",
        "        run_dir_v = f\"{run_dir}_{i}\"\n",
        "        if not os.path.exists(run_dir_v):\n",
        "            return run_dir_v\n",
        "        i += 1\n",
        "\n",
        "base_ckpt_dir = config['training'].get('checkpoint_dir', 'experiments/checkpoints')\n",
        "run_ckpt_dir = get_next_run_dir(base_ckpt_dir)\n",
        "config['training']['checkpoint_dir'] = run_ckpt_dir\n",
        "\n",
        "os.makedirs(run_ckpt_dir, exist_ok=True)\n",
        "print(f\"ðŸš€ Checkpoints will be saved to: {run_ckpt_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 134, Val samples: 34\n"
          ]
        }
      ],
      "source": [
        "# 4. Prepare Data\n",
        "mask_transform = MaskTubelet(\n",
        "    mask_ratio=config['data']['mask_ratio'],\n",
        "    patch_size=config['data']['patch_size']\n",
        ")\n",
        "\n",
        "# Load full dataset\n",
        "full_dataset = TubeletDataset(\n",
        "    manifest_path=config['data']['manifest_path'],\n",
        "    data_root=config['data'].get('data_root'),  # Handle relative paths\n",
        "    tubelet_size=config['data']['tubelet_size'],\n",
        "    transform=mask_transform\n",
        ")\n",
        "\n",
        "# Split train/val\n",
        "train_size = int(config['data']['train_split'] * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_ds, val_ds = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=config['training']['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=config['training']['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab8833db97344a30b3e92c8729e0b545",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/785 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63faaac22bb9402b971dcadce575024b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.30G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7163b3fc19d0497a879247d36d3736e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/587 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 5. Initialize Model\n",
        "model = JEPAModel(\n",
        "    encoder_name=config['model']['encoder_name'],\n",
        "    predictor_hidden=config['model']['predictor']['hidden_dim'],\n",
        "    predictor_dropout=config['model']['predictor']['dropout'],\n",
        "    freeze_encoder=config['model']['freeze_encoder']\n",
        ")\n",
        "\n",
        "device = torch.device(config['training']['device'])\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.predictor.parameters(),  # Only optimize predictor\n",
        "    lr=float(config['training']['lr']),\n",
        "    weight_decay=float(config['training']['weight_decay'])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… BENCHMARKING: Performance measurement utilities loaded\n"
          ]
        }
      ],
      "source": [
        "# BENCHMARKING: Performance measurement utilities\n",
        "import time\n",
        "import json\n",
        "import statistics\n",
        "import threading\n",
        "from collections import deque\n",
        "from pathlib import Path\n",
        "\n",
        "# BENCHMARKING: Configuration\n",
        "BENCHMARK_CONFIG = {\n",
        "    'warmup_iterations': 50,      # Ignore first N iterations\n",
        "    'benchmark_iterations': 300,   # Benchmark next M iterations\n",
        "    'nvidia_smi_interval': 0.25,   # Sample nvidia-smi every 250ms (if available)\n",
        "    'enable_nvidia_smi': True,     # Enable nvidia-smi sampling (optional)\n",
        "}\n",
        "\n",
        "# BENCHMARKING: Global state for benchmarking\n",
        "benchmark_state = {\n",
        "    'step_times': deque(maxlen=BENCHMARK_CONFIG['benchmark_iterations']),\n",
        "    'throughput': deque(maxlen=BENCHMARK_CONFIG['benchmark_iterations']),\n",
        "    'gpu_samples': [],\n",
        "    'nvidia_smi_thread': None,\n",
        "    'nvidia_smi_running': False,\n",
        "    'current_iteration': 0,\n",
        "    'benchmark_started': False,\n",
        "    'peak_memory_mb': 0.0,\n",
        "}\n",
        "\n",
        "def reset_memory_stats():\n",
        "    \"\"\"BENCHMARKING: Reset CUDA memory statistics.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def get_peak_memory_mb():\n",
        "    \"\"\"BENCHMARKING: Get peak allocated memory in MB.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "    return 0.0\n",
        "\n",
        "def sample_nvidia_smi():\n",
        "    \"\"\"BENCHMARKING: Sample nvidia-smi for GPU utilization and power (optional).\"\"\"\n",
        "    if not BENCHMARK_CONFIG['enable_nvidia_smi']:\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        import subprocess\n",
        "        result = subprocess.run(\n",
        "            ['nvidia-smi', '--query-gpu=utilization.gpu,power.draw', '--format=csv,noheader,nounits'],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=1.0\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            parts = result.stdout.strip().split(', ')\n",
        "            if len(parts) == 2:\n",
        "                return {\n",
        "                    'utilization_gpu': float(parts[0]),\n",
        "                    'power_draw': float(parts[1]),\n",
        "                    'timestamp': time.perf_counter()\n",
        "                }\n",
        "    except (FileNotFoundError, subprocess.TimeoutExpired, ValueError):\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def nvidia_smi_sampler():\n",
        "    \"\"\"BENCHMARKING: Background thread to sample nvidia-smi periodically.\"\"\"\n",
        "    while benchmark_state['nvidia_smi_running']:\n",
        "        sample = sample_nvidia_smi()\n",
        "        if sample:\n",
        "            benchmark_state['gpu_samples'].append(sample)\n",
        "        time.sleep(BENCHMARK_CONFIG['nvidia_smi_interval'])\n",
        "\n",
        "def start_nvidia_smi_sampling():\n",
        "    \"\"\"BENCHMARKING: Start background nvidia-smi sampling.\"\"\"\n",
        "    if BENCHMARK_CONFIG['enable_nvidia_smi'] and torch.cuda.is_available():\n",
        "        benchmark_state['nvidia_smi_running'] = True\n",
        "        benchmark_state['gpu_samples'] = []\n",
        "        benchmark_state['nvidia_smi_thread'] = threading.Thread(target=nvidia_smi_sampler, daemon=True)\n",
        "        benchmark_state['nvidia_smi_thread'].start()\n",
        "\n",
        "def stop_nvidia_smi_sampling():\n",
        "    \"\"\"BENCHMARKING: Stop background nvidia-smi sampling.\"\"\"\n",
        "    benchmark_state['nvidia_smi_running'] = False\n",
        "    if benchmark_state['nvidia_smi_thread']:\n",
        "        benchmark_state['nvidia_smi_thread'].join(timeout=1.0)\n",
        "\n",
        "def benchmarked_train_epoch(trainer, loader, epoch, batch_size):\n",
        "    \"\"\"\n",
        "    BENCHMARKING: Training epoch with per-iteration benchmarking.\n",
        "    Replicates trainer.train_epoch() logic but with instrumentation.\n",
        "    \"\"\"\n",
        "    from src.jepa.training.losses import jepa_loss\n",
        "    from tqdm import tqdm\n",
        "    \n",
        "    trainer.model.train()\n",
        "    trainer.model.encoder.eval()\n",
        "    trainer.model.predictor.train()\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    \n",
        "    # BENCHMARKING: Reset memory stats before training (only once, at start)\n",
        "    if epoch == 0 and not benchmark_state['benchmark_started']:\n",
        "        reset_memory_stats()\n",
        "        benchmark_state['benchmark_started'] = True\n",
        "        benchmark_state['current_iteration'] = 0  # Initialize global counter\n",
        "        start_nvidia_smi_sampling()\n",
        "    \n",
        "    pbar = tqdm(loader, desc=f\"Train Epoch {epoch}\")\n",
        "    for batch in pbar:\n",
        "        iter_start = time.perf_counter()\n",
        "        \n",
        "        # BENCHMARKING: Synchronize before timing\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        \n",
        "        # Move data to device\n",
        "        masked = batch[\"masked_frames\"].to(trainer.device)\n",
        "        clean = batch[\"clean_frames\"].to(trainer.device)\n",
        "        mask_frac = batch[\"mask_frac\"].to(trainer.device)\n",
        "        \n",
        "        # Forward pass\n",
        "        clean_emb, pred_emb = trainer.model(clean, masked, mask_frac)\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss = jepa_loss(pred_emb, clean_emb, normalize=True)\n",
        "        \n",
        "        # Backward pass\n",
        "        trainer.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        trainer.optimizer.step()\n",
        "        \n",
        "        # BENCHMARKING: Synchronize after computation\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        \n",
        "        iter_end = time.perf_counter()\n",
        "        iter_time_ms = (iter_end - iter_start) * 1000.0\n",
        "        \n",
        "        # Update metrics\n",
        "        loss_val = loss.item()\n",
        "        total_loss += loss_val\n",
        "        pbar.set_postfix({\"loss\": f\"{loss_val:.4f}\"})\n",
        "        \n",
        "        # BENCHMARKING: Collect metrics after warmup\n",
        "        if benchmark_state['current_iteration'] >= BENCHMARK_CONFIG['warmup_iterations']:\n",
        "            if len(benchmark_state['step_times']) < BENCHMARK_CONFIG['benchmark_iterations']:\n",
        "                benchmark_state['step_times'].append(iter_time_ms)\n",
        "                # Calculate throughput: batch_size images per iter_time_ms\n",
        "                images_per_sec = (batch_size * 1000.0) / iter_time_ms if iter_time_ms > 0 else 0.0\n",
        "                benchmark_state['throughput'].append(images_per_sec)\n",
        "                \n",
        "                # Update peak memory\n",
        "                current_peak = get_peak_memory_mb()\n",
        "                benchmark_state['peak_memory_mb'] = max(benchmark_state['peak_memory_mb'], current_peak)\n",
        "        \n",
        "        benchmark_state['current_iteration'] += 1\n",
        "    \n",
        "    # BENCHMARKING: Stop sampling if benchmark window is complete\n",
        "    if len(benchmark_state['step_times']) >= BENCHMARK_CONFIG['benchmark_iterations']:\n",
        "        stop_nvidia_smi_sampling()\n",
        "    \n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def print_benchmark_summary():\n",
        "    \"\"\"BENCHMARKING: Print concise benchmark summary.\"\"\"\n",
        "    if len(benchmark_state['step_times']) == 0:\n",
        "        print(\"\\nâš ï¸  BENCHMARKING: No benchmark data collected yet.\")\n",
        "        return\n",
        "    \n",
        "    step_times = list(benchmark_state['step_times'])\n",
        "    throughputs = list(benchmark_state['throughput'])\n",
        "    \n",
        "    mean_step_time = statistics.mean(step_times)\n",
        "    std_step_time = statistics.stdev(step_times) if len(step_times) > 1 else 0.0\n",
        "    \n",
        "    mean_throughput = statistics.mean(throughputs)\n",
        "    std_throughput = statistics.stdev(throughputs) if len(throughputs) > 1 else 0.0\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BENCHMARKING: Upstream Training Performance Summary\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Benchmark Window: {len(step_times)} iterations\")\n",
        "    print(f\"Warmup Iterations: {BENCHMARK_CONFIG['warmup_iterations']}\")\n",
        "    print()\n",
        "    print(\"Throughput:\")\n",
        "    print(f\"  Images/sec: {mean_throughput:.2f} Â± {std_throughput:.2f}\")\n",
        "    print(f\"  Clips/sec:  {mean_throughput:.2f} Â± {std_throughput:.2f}  (assuming 1 clip = 1 image)\")\n",
        "    print()\n",
        "    print(\"Step Time:\")\n",
        "    print(f\"  Average: {mean_step_time:.2f} Â± {std_step_time:.2f} ms/iter\")\n",
        "    print()\n",
        "    print(\"GPU Memory:\")\n",
        "    print(f\"  Peak Allocated VRAM: {benchmark_state['peak_memory_mb']:.2f} MB\")\n",
        "    \n",
        "    # BENCHMARKING: Optional nvidia-smi summary\n",
        "    if benchmark_state['gpu_samples']:\n",
        "        utilizations = [s['utilization_gpu'] for s in benchmark_state['gpu_samples']]\n",
        "        powers = [s['power_draw'] for s in benchmark_state['gpu_samples']]\n",
        "        mean_util = statistics.mean(utilizations)\n",
        "        mean_power = statistics.mean(powers)\n",
        "        \n",
        "        # Calculate energy per iteration (rough estimate)\n",
        "        if len(step_times) > 0:\n",
        "            avg_step_time_sec = mean_step_time / 1000.0\n",
        "            energy_per_iter = mean_power * avg_step_time_sec / 1000.0  # Joules per iteration\n",
        "        \n",
        "        print()\n",
        "        print(\"GPU Utilization (nvidia-smi):\")\n",
        "        print(f\"  Average GPU Utilization: {mean_util:.1f}%\")\n",
        "        print(f\"  Average Power Draw: {mean_power:.2f} W\")\n",
        "        if len(step_times) > 0:\n",
        "            print(f\"  Estimated Energy per Iteration: {energy_per_iter:.4f} J\")\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "\n",
        "def save_benchmark_results(output_dir):\n",
        "    \"\"\"BENCHMARKING: Save benchmark results to JSON file.\"\"\"\n",
        "    if len(benchmark_state['step_times']) == 0:\n",
        "        return\n",
        "    \n",
        "    step_times = list(benchmark_state['step_times'])\n",
        "    throughputs = list(benchmark_state['throughput'])\n",
        "    \n",
        "    results = {\n",
        "        'config': BENCHMARK_CONFIG,\n",
        "        'summary': {\n",
        "            'mean_step_time_ms': statistics.mean(step_times),\n",
        "            'std_step_time_ms': statistics.stdev(step_times) if len(step_times) > 1 else 0.0,\n",
        "            'mean_throughput_images_per_sec': statistics.mean(throughputs),\n",
        "            'std_throughput_images_per_sec': statistics.stdev(throughputs) if len(throughputs) > 1 else 0.0,\n",
        "            'peak_memory_mb': benchmark_state['peak_memory_mb'],\n",
        "            'benchmark_iterations': len(step_times),\n",
        "        },\n",
        "        'raw_data': {\n",
        "            'step_times_ms': step_times,\n",
        "            'throughput_images_per_sec': throughputs,\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Add nvidia-smi data if available\n",
        "    if benchmark_state['gpu_samples']:\n",
        "        utilizations = [s['utilization_gpu'] for s in benchmark_state['gpu_samples']]\n",
        "        powers = [s['power_draw'] for s in benchmark_state['gpu_samples']]\n",
        "        results['summary']['mean_gpu_utilization_percent'] = statistics.mean(utilizations)\n",
        "        results['summary']['mean_power_draw_watts'] = statistics.mean(powers)\n",
        "        results['raw_data']['gpu_samples'] = benchmark_state['gpu_samples']\n",
        "    \n",
        "    output_path = Path(output_dir) / 'benchmark_results.json'\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"\\nðŸ’¾ BENCHMARKING: Results saved to {output_path}\")\n",
        "\n",
        "print(\"âœ… BENCHMARKING: Performance measurement utilities loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:49<00:00,  2.93s/it, loss=0.0151]\n",
            "Val Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12<00:00,  2.59s/it, loss=0.0147]\n"
          ]
        }
      ],
      "source": [
        "# 6. Training Loop\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    checkpoint_dir=config['training']['checkpoint_dir']\n",
        ")\n",
        "\n",
        "# num_epochs = config['training']['epochs']\n",
        "num_epochs = 1\n",
        "best_loss = float('inf')\n",
        "batch_size = config['training']['batch_size']\n",
        "\n",
        "# BENCHMARKING: Use benchmarked training function for accurate measurements\n",
        "for epoch in range(num_epochs):\n",
        "    # BENCHMARKING: Use benchmarked_train_epoch instead of trainer.train_epoch\n",
        "    # This replicates the exact same training logic but with performance instrumentation\n",
        "    train_loss = benchmarked_train_epoch(trainer, train_loader, epoch, batch_size)\n",
        "    \n",
        "    # Validate (no benchmarking on validation)\n",
        "    val_loss = trainer.validate_epoch(val_loader, epoch)\n",
        "    \n",
        "    # Checkpoint\n",
        "    is_best = val_loss < best_loss\n",
        "    if is_best:\n",
        "        best_loss = val_loss\n",
        "        \n",
        "    if (epoch + 1) % config['training']['checkpoint_every'] == 0 or is_best:\n",
        "        trainer.save_checkpoint(epoch, val_loss, is_best, config)\n",
        "    \n",
        "    # BENCHMARKING: Print summary and save results when benchmark window is complete\n",
        "    if len(benchmark_state['step_times']) >= BENCHMARK_CONFIG['benchmark_iterations']:\n",
        "        if not benchmark_state.get('_summary_printed', False):\n",
        "            print_benchmark_summary()\n",
        "            save_benchmark_results(config['training']['checkpoint_dir'])\n",
        "            benchmark_state['_summary_printed'] = True\n",
        "\n",
        "# BENCHMARKING: Print final summary if training completes before benchmark window\n",
        "if len(benchmark_state['step_times']) > 0 and not benchmark_state.get('_summary_printed', False):\n",
        "    print_benchmark_summary()\n",
        "    save_benchmark_results(config['training']['checkpoint_dir'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
