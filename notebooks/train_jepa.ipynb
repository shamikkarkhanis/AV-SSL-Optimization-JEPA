{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# JEPA Training on Google Colab\n",
        "\n",
        "This notebook trains the JEPA model using the production package structure.\n",
        "It assumes the repository is cloned to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Locally\n"
          ]
        }
      ],
      "source": [
        "# 1. Environment Setup (Colab & Local Support)\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect environment\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running on Google Colab\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Path to repo in Drive (CHANGE THIS if needed)\n",
        "    REPO_PATH = '/content/drive/MyDrive/AV-SSL-Optimization-JEPA'\n",
        "    \n",
        "    if os.path.exists(REPO_PATH):\n",
        "        os.chdir(REPO_PATH)\n",
        "        print(f\"\ud83d\udcc2 Working directory set to: {os.getcwd()}\")\n",
        "        \n",
        "        # Install packages (Colab only)\n",
        "        print(\"\ud83d\udce6 Installing dependencies...\")\n",
        "        !pip install -e .[dev]\n",
        "        !pip install -r requirements.txt\n",
        "    else:\n",
        "        print(f\"\u26a0\ufe0f Repo not found at {REPO_PATH}. Please clone it to Drive first.\")\n",
        "\n",
        "else:\n",
        "    print(\"Running Locally\")\n",
        "    # If running from 'notebooks/' directory, move up to root\n",
        "    current_dir = os.getcwd()\n",
        "    if current_dir.endswith('notebooks'):\n",
        "        os.chdir('..')\n",
        "        print(f\"Moved up to project root: {os.getcwd()}\")\n",
        "    \n",
        "    # Add project root to sys.path to find 'src' module\n",
        "    if os.getcwd() not in sys.path:\n",
        "        sys.path.append(os.getcwd())\n",
        "        print(\"Added project root to sys.path\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shamik/Documents/AV-SSL-Optimization-JEPA/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# 3. Load Configuration\n",
        "import yaml\n",
        "import torch\n",
        "from src.jepa.data import JEPADataset, TubeletDataset, MaskTubelet\n",
        "from src.jepa.models import JEPAModel\n",
        "from src.jepa.training import Trainer\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Load default config\n",
        "with open('configs/default.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Override config for Colab if needed\n",
        "config['training']['batch_size'] = 8  # Adjust based on GPU VRAM\n",
        "config['training']['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f\"Using device: {config['training']['device']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'videomae/clips_manifest.jsonl'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m mask_transform = MaskTubelet(\n\u001b[32m      3\u001b[39m     mask_ratio=config[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmask_ratio\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      4\u001b[39m     patch_size=config[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mpatch_size\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load full dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m full_dataset = \u001b[43mTubeletDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanifest_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvideomae/clips_manifest.jsonl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Path to your manifest\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtubelet_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtubelet_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_transform\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Split train/val\u001b[39;00m\n\u001b[32m     15\u001b[39m train_size = \u001b[38;5;28mint\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtrain_split\u001b[39m\u001b[33m'\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(full_dataset))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AV-SSL-Optimization-JEPA/src/jepa/data/dataset.py:105\u001b[39m, in \u001b[36mTubeletDataset.__init__\u001b[39m\u001b[34m(self, manifest_path, tubelet_size, transform)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    101\u001b[39m     manifest_path: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m    102\u001b[39m     tubelet_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m2\u001b[39m,\n\u001b[32m    103\u001b[39m     transform=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    104\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28mself\u001b[39m.base_dataset = \u001b[43mJEPADataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanifest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m.tubelet_size = tubelet_size\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mself\u001b[39m.transform = transform\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AV-SSL-Optimization-JEPA/src/jepa/data/dataset.py:43\u001b[39m, in \u001b[36mJEPADataset.__init__\u001b[39m\u001b[34m(self, manifest_path, transform, frames_per_clip)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mself\u001b[39m.frames_per_clip = frames_per_clip\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Load all manifest lines into memory\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmanifest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m.lines = f.read().splitlines()\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'videomae/clips_manifest.jsonl'"
          ]
        }
      ],
      "source": [
        "# 4. Prepare Data\n",
        "mask_transform = MaskTubelet(\n",
        "    mask_ratio=config['data']['mask_ratio'],\n",
        "    patch_size=config['data']['patch_size']\n",
        ")\n",
        "\n",
        "# Load full dataset\n",
        "full_dataset = TubeletDataset(\n",
        "    manifest_path='data/manifests/clips_manifest.jsonl',  # Path to your manifest\n",
        "    tubelet_size=config['data']['tubelet_size'],\n",
        "    transform=mask_transform\n",
        ")\n",
        "\n",
        "# Split train/val\n",
        "train_size = int(config['data']['train_split'] * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_ds, val_ds = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=config['training']['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=config['training']['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Initialize Model\n",
        "model = JEPAModel(\n",
        "    encoder_name=config['model']['encoder_name'],\n",
        "    predictor_hidden=config['model']['predictor']['hidden_dim'],\n",
        "    predictor_dropout=config['model']['predictor']['dropout'],\n",
        "    freeze_encoder=config['model']['freeze_encoder']\n",
        ")\n",
        "\n",
        "device = torch.device(config['training']['device'])\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.predictor.parameters(),  # Only optimize predictor\n",
        "    lr=float(config['training']['lr']),\n",
        "    weight_decay=float(config['training']['weight_decay'])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Training Loop\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    checkpoint_dir=config['training']['checkpoint_dir']\n",
        ")\n",
        "\n",
        "num_epochs = config['training']['epochs']\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    train_loss = trainer.train_epoch(train_loader, epoch)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss = trainer.validate_epoch(val_loader, epoch)\n",
        "    \n",
        "    # Checkpoint\n",
        "    is_best = val_loss < best_loss\n",
        "    if is_best:\n",
        "        best_loss = val_loss\n",
        "        \n",
        "    if (epoch + 1) % config['training']['checkpoint_every'] == 0 or is_best:\n",
        "        trainer.save_checkpoint(epoch, val_loss, is_best, config)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}